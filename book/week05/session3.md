# 머신러닝 모델의 학습과 평가

## 머신러닝 모델 최적화의 기초

### 목표와 개요

```{image} figs/image-3-1-1.jpeg
:width: 90%
:align: center
```

- 머신러닝 모델 최적화는 모델의 예측 성능을 극대화하는 과정입니다.
- 이 과정을 통해 데이터의 패턴을 더 잘 이해하고, 실제 세계의 복잡한 문제를 해결할 수 있습니다.

### 선형 회귀 모델의 기본 개념

```{image} figs/image-3-1-2.jpeg
:width: 90%
:align: center
```

- 선형 회귀 모델은 가장 기본적인 머신러닝 모델 중 하나입니다.
- 이 모델은 데이터의 관계를 y = ax + b 형태의 직선으로 나타냅니다.
  - 여기서 y는 종속 변수, x는 독립 변수, a는 기울기, b는 y절편입니다.
- 선형 회귀는 데이터 포인트들과 가장 잘 맞는 직선을 찾는 과정입니다.

### 최소 제곱법 소개

```{image} figs/image-3-1-3.jpeg
:width: 90%
:align: center
```

- 최소 제곱법은 선형 회귀 모델에서 매개변수 a와 b를 찾는 표준 방법입니다.
- 이 방법은 데이터 포인트와 선형 모델 간의 거리(오차)의 제곱을 최소화합니다.
- 수학적으로는 오차의 제곱 합을 최소화하는 a와 b를 찾는 것을 의미합니다.

### 평균 제곱 오차(MSE) 이해

```{image} figs/image-3-1-4.jpeg
:width: 90%
:align: center
```

- 평균 제곱 오차(MSE)는 모델의 예측값과 실제값 간의 차이를 수치화하는 방법입니다.
- MSE = (1/n) Σ(actual - prediction)²
  - 여기서 n은 샘플의 수, actual은 실제값, prediction은 예측값입니다.
- MSE가 작을수록 모델의 예측 성능이 좋다고 할 수 있습니다.
- MSE는 모델의 성능을 평가하고 비교하는 데 중요한 지표로 사용됩니다.

## 비용함수와 손실함수

### 비용함수와 손실함수의 정의

- **정의**:
  - 손실함수(Loss Function): 개별 데이터 포인트에 대한 모델의 오차를 측정합니다.
  - 비용함수(Cost Function): 전체 데이터셋에 대한 모델의 성능을 측정합니다.
- **중요성**:
  - 이 함수들은 모델이 얼마나 잘 또는 잘못 예측하는지를 나타내며, 이를 최소화하는 것이 모델 학습의 목표입니다.

### 평균제곱오차의 역할

- **평균 제곱 오차(Mean Squared Error, MSE)**:
  - MSE = (1/n) Σ(actual - prediction)²
  - 여기서 Σ는 합계, n은 샘플 수, actual은 실제 값, prediction은 예측 값입니다.
- **역할**:
  - MSE는 회귀 문제에서 자주 사용되는 손실 함수입니다.
  - 모델의 예측과 실제 값 사이의 거리를 제곱하여 평균을 내, 오차의 크기를 나타냅니다.

### 오차 함수와 목적 함수의 비교

- **오차 함수(Error Function)**:
  - 개별 예측값과 실제값의 차이를 측정합니다.
  - 주로 손실 함수로 사용되며, 모델이 개별 데이터 포인트에서 얼마나 잘못 예측하는지를 나타냅니다.
- **목적 함수(Objective Function)**:
  - 전체 데이터셋을 기반으로 한 모델의 전반적인 성능을 측정합니다.
  - 비용 함수와 같은 의미로 사용되며, 모델의 성능 최적화를 위한 목표를 설정합니다.
- **차이점**:
  - 오차 함수는 개별 데이터 포인트에 초점을 맞추고, 목적 함수는 전체 데이터셋에 대한 성능을 고려합니다.

## 경사하강법 (Gradient Descent)

- **경사하강법의 기본 원리**
  - 비용함수의 최소점을 찾기 위해 기울기(gradient)를 사용하는 방법.
- **경사하강법의 다양한 변형**
  - 다양한 변형 방법(SGD, Momentum 등)과 각각의 특징 및 적용 상황.
- **경사하강법 시각화**
  - 비용함수의 모양과 경사하강법의 경로를 시각적으로 이해하기.

## 머신러닝 모델의 일반화

- **과대적합과 과소적합**
  - 모델이 학습 데이터에 지나치게 적합되거나, 충분히 학습되지 않는 현상.
- **최적화 알고리즘의 중요성**
  - 모델의 일반화 능력을 향상시키는 최적화 알고리즘.
- **과대적합과 과소적합 방지 전략**
  - 데이터 증강, 교차 검증, 정규화 기법 등의 전략 소개.

## 좋은 머신러닝 모델의 조건

- **데이터의 양과 질의 중요성**
  - 충분하고 다양한, 고품질의 데이터의 중요성 강조.
- **모델 복잡도 조절**
  - PCA 등을 사용하여 모델의 복잡도 및 특성 수를 조절하는 방법.
- **일반화, 정규화, 가중치 규제**
  - 모델의 과적합을 방지하고 일반화 성능을 향상시키는 기법들 소개.
